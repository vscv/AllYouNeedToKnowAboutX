* * *
[OOM]

OOMæœ‰å…©ç¨®ï¼Œhost CPUèˆ‡GPUã€‚

CPU: 

ä¸è¦ç›´æ¥å°‡datasetè¼‰å…¥è¨˜æ†¶é«”ä¸­ä½¿ç”¨ï¼Œæœ€å¥½ç”¨tf.dataã€tfrecordä¾†è™•ç†ã€‚

GPU:

æ¸›å°‘batch sizeï¼Œæ¸›å°‘è¼¸å…¥å½±åƒçš„è§£æåº¦ï¼Œä½¿ç”¨æ··åˆç²¾åº¦ã€‚

(transfer learningå¯ä»¥è·‘ï¼Œfine tuneingå°±OOMï¼Ÿ å•é¡Œä¸€æ¨£ï¼Œfine tuneæœƒ`çœŸçš„`å•Ÿç”¨æ‰€æœ‰åƒæ•¸å› æ­¤éœ€è¦çš„GPUè¨˜æ†¶é«”æœƒæ›´å¤šï¼)

è¿‘å¹´GPUè¨˜æ†¶é«”è¦æ ¼ï¼š

V100 32GB

A100 80GB

H100 80GB

â­•ï¸ è‡³å°‘V100å°±è·‘ä¸äº†EfficientNet-V2-XLçš„fine tuning!!!



â­•ï¸ æ²’è³‡æºçš„è©±å¯ä»¥ä¸Škaggleè¨»å†Šï¼Œä¸€é€±æœ‰20å°æ™‚çš„TPUå¯ä»¥ä½¿ç”¨ã€‚

TPU: 

e.g. "TPU v3-8" 8æ ¸å¿ƒ 128GB memory

  EfficientNet-V2-XL: Fine-tune, bs=64 <-- BATCH_SIZE = 8 * strategy.num_replicas_in_sync 

    INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.
    INFO:tensorflow:Initializing the TPU system: local
    INFO:tensorflow:Finished initializing TPU system.
    INFO:tensorflow:Found TPU system:
    INFO:tensorflow:*** Num TPU Cores: 8
    INFO:tensorflow:*** Num TPU Workers: 1
    INFO:tensorflow:*** Num TPU Cores Per Worker: 8
    INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
    INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)
    INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)
    INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)
    INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)
    INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)
    INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)
    INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)
    INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)
    INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
    /QK/ TPU!
    Number of accelerators:  8


    model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp. `é€™å€‹ç›®å‰ç„¡è§£ï¼Œåƒ…æ˜¯è­¦å‘Šé‚„æ˜¯å¯ä»¥è¨“ç·´çš„ã€‚`


* log

    
      Epoch 1: val_loss improved from inf to 229.27214, saving model to best_my_model_20230904_bs8_reduce_lr_efnv2xl_fine_tune_TPU/saved_weight
      4/4 [==============================] - 714s 101s/step - loss: 449.7910 - mean_squared_error: 449.7810 - mean_absolute_error: 18.9748 - root_mean_squared_error: 21.2080 - val_loss: 229.2721 - val_mean_squared_error: 229.2620 - val_mean_absolute_error: 14.2356 - val_root_mean_squared_error: 15.1414 - lr: 0.0010
      Epoch 2/1000
      4/4 [==============================] - ETA: 0s - loss: 269.9185 - mean_squared_error: 269.9084 - mean_absolute_error: 14.9394 - root_mean_squared_error: 16.4289
      ...
      ...
      Epoch 156: val_loss did not improve from 55.49997
      4/4 [==============================] - 4s 1s/step - loss: 39.4206 - mean_squared_error: 39.4083 - mean_absolute_error: 4.6351 - root_mean_squared_error: 6.2776 - val_loss: 80.0362 - val_mean_squared_error: 80.0239 - val_mean_absolute_error: 6.6511 - val_root_mean_squared_error: 8.9456 - lr: 1.0000e-09


* download model/data from kaggle working

`!tar cvf best_my_model_20230904_bs8_reduce_lr_efnv2xl_fine_tune_TPU.tar /kaggle/working/best_my_model_20230904_bs8_reduce_lr_efnv2xl_fine_tune_TPU/`

```python
from IPython.display import FileLink
FileLink(r'best_my_model_20230904_bs8_reduce_lr_efnv2xl_fine_tune_TPU.tar')
```

* ç”¢ç”Ÿä¸€å€‹ä¸‹è¼‰é€£çµ
![image](https://github.com/vscv/AllYouNeedToKnowAboutX/assets/18000764/f662f950-ceea-40ec-807a-55999800ae1d)


  
* * *

### 2023-03-25 âš  Bug Trace âš 

* è¨ˆç®—é æ¸¬å½±åƒå“è³ªçš„æŒ‡æ¨™æ•¸æ“šéå¸¸çš„å¥½ï¼ 
`(æ•¸æ“šå¤ªå¥½æ‰æ˜¯ç–‘å•çš„é–‹å§‹!)`

ç•¶çœ‹åˆ°MSEé å°æ–¼MAEæ™‚ï¼Œç™¼ç”Ÿäº†ä»€éº¼äº‹æƒ…ï¼Ÿ

ç”±æ–¼MSEæ˜¯å–å·®å€¼å†å¹³æ–¹ï¼Œä½†æ˜¯Tensorå„²å­˜æ™‚å·²ç¶“å…ˆè½‰æˆ[0,1]äº†ï¼Œå› æ­¤è¨ˆç®—MSEçš„å·®å€¼éƒ½æœƒå°æ–¼1ä½¿å¾—å¹³æ–¹æ™‚ä½¿æ•¸å€¼è®Šå¾—æ›´å°äº†ã€‚

[ToDo]è¨ˆç®—MAE MSE PSNR SSIMæ™‚ å¿…é ˆæŠŠscaleè½‰å›[0,255]ä¹‹å¾Œæ‰èƒ½æ­£ç¢ºåœ°è¨ˆç®—ï¼



* * *
## å·²ç¶“çµ‚æ­¢çš„GPUé€²ç¨‹ç„¡æ³•æ ¹æ“šnvidia-smiå‘½ä»¤çš„PIDæ®ºæ­»çš„å•é¡Œè§£æ±ºæ–¹æ¡ˆ

  ```python
  https://zhuanlan.zhihu.com/p/506686899
  é¦–å…ˆä½¿ç”¨linuxä¸­çš„fuseråº«ï¼Œé€™å€‹åº«åœ¨æˆ‘çš„ç’°å¢ƒä¸­ä¸æ˜¯è‡ªå¸¶çš„åº«ï¼Œæ‰€ä»¥éœ€è¦ä¸‹è¼‰ã€‚
  ä¸‹è¼‰å‘½ä»¤å¦‚ä¸‹ï¼š
  apt install psmisc
  å®‰è£ä¹‹å¾Œä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ï¼š
  fuser -v /dev/nvidia*
  åœ¨çµæœä¸­ç™¼ç¾ï¼Œåœ¨ä¸åŒçš„GPUä¸Šéƒ½æœ‰åŒä¸€å€‹é€²ç¨‹ï¼Œé€²ç¨‹è™Ÿç‚º"53940"ã€‚
  ç‚ºäº†ç¢ºå®šé€™å€‹é€²ç¨‹æ˜¯ä¸æ˜¯æˆ‘å€‘é‹è¡Œçš„ç¨‹åºï¼Œæˆ‘å€‘ä½¿ç”¨å¦‚ä¸‹çš„æ–¹å¼ä¾†æŸ¥çœ‹ä¸€ä¸‹é€™å€‹é€²ç¨‹çš„ä¿¡æ¯ã€‚
  ps -ef|grep 53940
  æœ€å¾Œä½¿ç”¨ä¸Šè¿°æåˆ°çš„åˆªé™¤é€²ç¨‹çš„æ–¹æ³•ã€‚
  kill -9 53940
  æ›´æ–°ï¼š
  å¾åˆ¥äººçš„åšå®¢è£¡é¢çœ‹åˆ°çš„ï¼Œæ‰¹é‡åˆªé™¤é€²ç¨‹çš„code
  sudo fuser -v /dev/nvidia* |awk '{for(i=1;i<=NF;i++)print "kill -9 " $i;}' | sudo sh
  æˆ–è€…é‡å°æŸä¸€å€‹GPUåˆªé™¤é€²ç¨‹çš„code
  sudo fuser -v /dev/nvidia2 |awk '{for(i=1;i<=NF;i++)print "kill -9 " $i;}' | sudo sh
  åƒè€ƒï¼š {ä¸è¦åŠ sudo!}
  ```

* * *

### TF Tensor å°Maskå½±åƒå€¼é€²è¡Œéæ¿¾

##### mask = [1 if x > 0.5 else 0 for x in mask]
ğ‘“(ğ‘¥)={(1, ğ‘–ğ‘“ ğ‘¥â‰¥0.5  0, ğ‘’ğ‘™ğ‘ ğ‘’.)
<img width="236" alt="image" src="https://github.com/vscv/AllYouNeedToKnowAboutX/assets/18000764/04c672b0-31ae-49a6-bdd2-13bc3177c488">

ä¸Š:è¼¸å…¥ ä¸­:åˆ†å‰²çµæœ ä¸‹:åˆ†å‰²éæ¿¾
<img width="236" alt="image" src="https://github.com/vscv/AllYouNeedToKnowAboutX/assets/18000764/23066424-a1f4-404a-a4de-4fffe7afc39a">

`tf.where`
```python
mask = tf.constant([[0.1,0.2,0.6,0.7], [0.5,0.7,0.3,0.4]])
tf.where(mask >= 0.5, 1, 0)

<tf.Tensor: shape=(2, 4), dtype=int32, numpy=
array([[0, 0, 1, 1],
       [1, 1, 0, 0]], dtype=int32)>
       
tf.where(mask > 0.5, 1, 0)

<tf.Tensor: shape=(2, 4), dtype=int32, numpy=
array([[0, 0, 1, 1],
       [0, 1, 0, 0]], dtype=int32)>
```

`tf.cast`
é€™æ˜¯åˆ©ç”¨castæˆæ•´æ•¸å‹æ…‹æ™‚æœƒ~~è‡ªå‹•å››æ¨äº”å…¥~~ ï¼Œç®—flooråœ¨è½‰å‹æ…‹ã€‚

```python
mask = tf.constant([[0.1,0.2,0.6,1.7], [0.5,0.7,0.3,0.4]])
tf.cast(mask + 0.5, tf.int32)
<tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[0., 0., 0., 1.],
       [0., 0., 0., 0.]], dtype=float32)>
```

`tf.floor`å–æœ€å¤§æ•´æ•¸ 1.7->1 # æ¨å»å°æ•¸å¾Œæœ€å¤§æ•´æ•¸
```python
tf.floor([0.1, 0.5, 0.9, 1.2, 1.9])
<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 1., 1.], dtype=float32)>
```

`tf.round` # å››æ¨å…­å…¥äº”å–å¶ï¼Œç•¶å°æ•¸ç‚º0.5è‹¥æ•´æ•¸ç‚ºå¶æ•¸å‰‡æ¨å»å°æ•¸å–å¶æ•¸ï¼Œè‹¥ç‚ºå¥‡æ•¸å‰‡é€²ä½ã€‚

```python
tf.round([0.1, 1.5, 2.5, 0.5, 0.6, 1.2, 1.9])
<tf.Tensor: shape=(7,), dtype=float32, numpy=array([0., 2., 2., 0., 1., 1., 2.], dtype=float32)>
```

* * *
## kaggle ç„¡ç¶²è·¯ç’°å¢ƒä¸‹ï¼Œé å…ˆä¸‹è¼‰å¥—ä»¶å†é›¢ç·šå®‰è£
https://www.kaggle.com/competitions/severstal-steel-defect-detection/discussion/113195

* å–å¾—wheelæª”
```bash
#pip download [package_name], then you will get the whl file.

""" put a lot of wheels in dir """
mkdir wheels_dir
cd wheels_dir/
pip download segmentation-models
```

* æ”¾å…¥kaggle-> datasetè‡ªè¨‚ä¸­ï¼Œå†ç”±æœ¬åœ°å®‰è£
```bash
!pip install segmentation-models --no-index --find-links=file:///kaggle/input/wheels_dir/
```

* * *
# tf.image.resize, tf.image.resize_with_pad
`todo:å›å‚³dtypeå·®ç•°ï¼Œä»¥åŠåŸå§‹



* * *
# tensorboard

```bash
$tensorboard --logdir train_log/20231223-203132 --port 5000

# --port è‹¥åœ¨å…¬æœ‰é›²è«‹è¨­æˆ
#ç›®æ¨™åŸ : 5000 (userdefine1)å…§éƒ¨å¯è¦‹
#å°å¤–åŸ : 55955 (å¤–éƒ¨å¯è¦‹)
```

* tensorboard dev
`tensorboard dev upload --logdir {logs/}`
`2023/11/31çµ‚æ­¢è©²devç·šä¸Šæœå‹™ï¼Œè«‹ç”¨å›æœ¬åœ°tensorboardï¼`

* tensorboard.data.experimental.ExperimentFromDev()
`åƒ…æ”¯æ´è®€å–tensorboard devçš„ç·šä¸Šä½å€ï¼Œå› æ­¤ä¹Ÿç„¡æ³•ä½¿ç”¨äº†ã€‚`

* from tensorboard.backend.event_processing.event_file_loader import RawEventFileLoader
https://github.com/tensorflow/tensorboard/issues/6388
```python
from tensorboardX import SummaryWriter
from tensorboard.backend.event_processing.event_file_loader import RawEventFileLoader
from tensorboard.compat.proto import event_pb2

loader = RawEventFileLoader("{path_to_your_logdir}/events.out.tfevents.{old_suffix}.ps") # it is a file name, need to add "ps"
events = []
for raw_event in loader.Load():
    e = event_pb2.Event.FromString(raw_event)
    # print(e)
    # print(e.step) # the "step" in my result is the index of training epoch, I want to choose the last 20 epochs.
    if e.step <= 100 and e.step > 80:
            events.append(e)

tb_log = SummaryWriter(log_dir="{path_to_your_logdir}/events") # it is a path, not a file, I create a folder called events
for e in events[1:]:   

    # For me, the first element in "events" seems not the result data, you can print "events[0:2]" to check it.
    # print(events[0:2])

    # wall_time: 1684237044.4711838
    # file_version: "brain.Event:2"

    # wall_time: 1684237250.0319963
    # step: 81
    # summary {
    #  value {
               # tag: "recall/roi_0.3"
               # simple_value: 0.9507125616073608
    # }
    # }

    # print(e.summary.value)
    # print(type(e.summary.value))
    for value in e.summary.value:
        # print(value.tag,value.simple_value, e.step)
        tb_log.add_scalar(str(value.tag),value.simple_value, e.step)
```



* * *
## PyTorch test

```python
import torch
import torch.nn as nn

print(f"What about a GPU? {torch.cuda.is_available()}")

print(f"Number about GPU? {torch.cuda.device_count()}")

print(f"What current GPU? {torch.cuda.current_device()}")

print(f"What name is GPU? {torch.cuda.get_device_name(torch.cuda.current_device())}")

print(f"Set default tensor type to CUDA: {torch.set_default_tensor_type(torch.cuda.FloatTensor)}")

print(f"Are tensors stored on GPU by default? {torch.rand(10).device}")
```


    What about a GPU? True
    Number about GPU? 1
    What current GPU? 0
    What name is GPU? Tesla V100-SXM2-32GB
    Set default tensor type to CUDA: None
    Are tensors stored on GPU by default? cuda:0
    torch_ver_major:1, dtype_index:torch.int64



* * *

* * *
* tfb with jupyter notebook
* * *


***
[TODO test]


https://www.tensorflow.org/guide/distributed_training
å°‡ tf.distribute.Strategy èˆ‡è‡ªè¨‚è¨“ç·´å¾ªç’°çµåˆä½¿ç”¨
å¦‚ä¸Šæ‰€ç¤ºï¼Œtf.distribute.Strategyèˆ‡ Keras ä¸€èµ·ä½¿ç”¨Model.fitåªéœ€æ›´æ”¹å¹¾è¡Œç¨‹å¼ç¢¼ã€‚åªè¦å¤šä¸€é»åŠªåŠ›ï¼Œæ‚¨é‚„å¯ä»¥ä½¿ç”¨è‡ªè¨‚è¨“ç·´å¾ªç’°ã€‚tf.distribute.Strategy

å¦‚æœæ‚¨éœ€è¦æ¯” Estimator æˆ– Keras æ›´å¤§çš„éˆæ´»æ€§å’Œå°è¨“ç·´å¾ªç’°çš„æ§åˆ¶ï¼Œæ‚¨å¯ä»¥ç·¨å¯«è‡ªè¨‚è¨“ç·´å¾ªç’°ã€‚ä¾‹å¦‚ï¼Œç•¶ä½¿ç”¨ GAN æ™‚ï¼Œæ‚¨å¯èƒ½å¸Œæœ›æ¯è¼ªæ¡ç”¨ä¸åŒæ•¸é‡çš„ç”Ÿæˆå™¨æˆ–åˆ¤åˆ¥å™¨æ­¥é©Ÿã€‚åŒæ¨£ï¼Œé«˜éšæ¡†æ¶ä¹Ÿä¸å¤ªé©åˆå¼·åŒ–å­¸ç¿’è¨“ç·´ã€‚



ç„¶å¾Œï¼Œå®šç¾©è¨“ç·´çš„ä¸€å€‹æ­¥é©Ÿã€‚ç”¨æ–¼tf.GradientTapeè¨ˆç®—æ¢¯åº¦å’Œæœ€ä½³åŒ–å™¨æ‡‰ç”¨é€™äº›æ¢¯åº¦ä¾†æ›´æ–°æ¨¡å‹çš„è®Šæ•¸ã€‚è‹¥è¦åˆ†ç™¼æ­¤è¨“ç·´æ­¥é©Ÿï¼Œè«‹å°‡å…¶æ”¾å…¥å‡½æ•¸ä¸­ä¸¦å°‡å…¶èˆ‡å¾å…ˆå‰å»ºç«‹çš„è³‡æ–™é›†è¼¸å…¥ä¸€èµ·train_stepå‚³éï¼štf.distribute.Strategy.rundist_dataset




https://link.springer.com/article/10.1007/s11227-022-04354-1

https://media.springernature.com/full/springer-static/image/art%3A10.1007%2Fs11227-022-04354-1/MediaObjects/11227_2022_4354_Fig1_HTML.png![image](https://github.com/user-attachments/assets/09ff402a-8d8b-4d41-a630-4fbcefae5e17)

Fig. 1



å¦‚ä¸Šæ‰€è¿°ï¼ŒåŸ·è¡Œå½±åƒè®Šæ›ä»»å‹™çš„ç”Ÿæˆå°æŠ—ç¥ç¶“ç¶²è·¯è‡³å°‘åŒ…å«å¤šå€‹ç¥ç¶“ç¶²è·¯ä»¥åŠå¤šå€‹æå¤±å‡½æ•¸ã€‚é€™ä½¿å¾—é€™äº›ç¶²è·¯çš„è¨“ç·´ç›¸ç•¶æ˜‚è²´ã€‚ç‚ºäº†æ¸›å°‘è¨“ç·´æ™‚é–“ï¼Œ[ 21 ]ä¸­æå‡ºäº†ä¸€ç¨®æ¼”åŒ–æ¼”ç®—æ³•ï¼Œå®ƒå¯ä»¥ç©©å®šç¬¬ä¸€æ¬¡è¿­ä»£ä¸­çš„æ¬Šé‡ï¼Œä»¥é¿å…å´©æ½°ï¼ˆç¸½æ˜¯å¾è¼¸å…¥å½±åƒç”¢ç”Ÿç›¸åŒçš„è¼¸å‡ºï¼‰å’Œä¸æ”¶æ–‚ï¼ˆè®Šæ›æ°¸é ä¸æœƒç™¼ç”Ÿï¼‰å•é¡Œã€‚è©²æ–¹æ³•å¯¦ç¾äº†æ›´å¿«çš„æ”¶æ–‚ã€‚ç„¶è€Œï¼Œè©²è§£æ±ºæ–¹æ¡ˆä¸¦æ²’æœ‰é¡¯è‘—æé«˜ç³»çµ±çš„è¨“ç·´é€Ÿåº¦ï¼Œå› ç‚ºå®ƒæ²’æœ‰åˆ©ç”¨ä¸»è¦ç‚ºç³»çµ±æä¾›é€Ÿåº¦çš„ç¡¬é«”è³‡æºã€‚åœ¨[ 22 ]ä¸­ï¼Œä½œè€…è¨“ç·´äº† Lapras-GANï¼Œé€™æ˜¯ä¸€ç¨®åˆ©ç”¨ SSIM å’Œ L1 ä¾†ç²å¾—é€¼çœŸå½±åƒçš„å½±åƒè¶…è§£æåº¦æ–¹æ³•ã€‚ç‚ºäº†åŸ·è¡Œ PyTorch è¨“ç·´ï¼Œä½¿ç”¨å¤šå€‹å…·æœ‰å¤šå€‹ GPU çš„ç¯€é»ï¼Œå°‡è¨“ç·´æ™‚é–“æ¸›å°‘å¤šé” 4 å€ã€‚åœ¨VAE-GAN[ 23 ]ä¸­ï¼ŒTensorFlowç”¨æ–¼åŸ·è¡Œå¤šGPUè¨“ç·´ã€‚ç°¡è€Œè¨€ä¹‹ï¼Œå¤šå€‹ GPU çš„çµåˆå¯ä»¥é¡¯è‘—æé«˜è¨“ç·´é€Ÿåº¦ã€‚ç„¶è€Œï¼Œä¸Šè¿°çš„è§£æ±ºæ–¹æ¡ˆï¼ˆPix2Pixã€CycleGANã€BicycleGANï¼‰ä¸åŒ…æ‹¬å¤š GPU è¨“ç·´ã€‚

å› æ­¤ï¼Œç‚ºäº†åˆ©ç”¨è¨“ç·´é€Ÿåº¦ï¼Œæœ‰å¿…è¦å¢åŠ è¨“ç·´æ‰¹æ¬¡çš„å¤§å°ã€‚æ­¤åƒæ•¸åœ¨è¨“ç·´ä¸­éå¸¸é‡è¦ï¼Œå› ç‚ºéå¸¸å¤§çš„æ‰¹é‡å¤§å°å¯ä»¥ä½¿è¨“ç·´é€Ÿåº¦æ›´å¿«ï¼Œä½†å¯èƒ½æœƒå°è‡´æ¨¡å‹éåº¦æ³›åŒ–ä¸¦ä¸”ç„¡æ³•è½‰æ›å½±åƒç´°ç¯€ã€‚åœ¨ä¸€äº›å·¥ä½œä¸­ï¼Œæå‡ºäº†ä¸€äº›æ ¹æ“šéç”Ÿæˆå°æŠ—ç¶²çµ¡ä¸­çš„ç´€å…ƒ [ 24 , 25 ] å’Œç¶²çµ¡å±¤ [ 26 ] æ”¹è®Šæ‰¹é‡å¤§å°çš„ç­–ç•¥ã€‚

ç„¶è€Œï¼Œå…ˆå‰å°šæœªç ”ç©¶é GANï¼ˆPix2Pix æˆ– CycleGANï¼‰ä¸­æ‰¹é‡å¤§å°å¢åŠ çš„å½±éŸ¿ã€‚åœ¨é€™äº›è§£æ±ºæ–¹æ¡ˆä¸­ï¼Œåœ¨ä¸åŒè«–æ–‡ä¸­å»ºç«‹äº†æ‰¹é‡å¤§å°ï¼Œä½†ä¸å»ºè­°å¢åŠ æ‰¹é‡å¤§å°ã€‚
***


---
### è¨“ç·´ Ultralytics YOLOv12 æ¨¡å‹çš„å–® GPU èˆ‡å¤š GPU è¶…åƒæ•¸è€ƒé‡

åœ¨ Ultralytics å¥—ä»¶ä¸­è¨“ç·´ YOLOv12 æ¨¡å‹æ™‚ï¼Œä½¿ç”¨å–®å¼µ GPU èˆ‡å¤šå¼µ GPU åŠ é€Ÿçš„ä¸»è¦å·®ç•°åœ¨æ–¼ä¸¦è¡Œè¨ˆç®—çš„è¦æ¨¡ï¼Œé€™æœƒå½±éŸ¿è¶…åƒæ•¸çš„è¨­å®šï¼Œå°¤å…¶æ˜¯ batch size å’Œ learning rateï¼ˆå­¸ç¿’ç‡ï¼‰ã€‚å–® GPU è¨“ç·´å—é™æ–¼å–®ä¸€ GPU çš„è¨˜æ†¶é«”å’Œè¨ˆç®—è³‡æºï¼Œé©åˆå°è¦æ¨¡å¯¦é©—ï¼›å¤š GPU å‰‡é€é Data Parallelismï¼ˆè³‡æ–™ä¸¦è¡Œï¼‰åˆ†æ“”è² è¼‰ï¼Œèƒ½å¤§å¹…ç¸®çŸ­è¨“ç·´æ™‚é–“ï¼Œä½†éœ€èª¿æ•´è¶…åƒæ•¸ä»¥ç¶­æŒæ¨¡å‹æ”¶æ–‚ç©©å®šæ€§ã€‚ä»¥ä¸‹é‡é»èªªæ˜é—œéµè€ƒé‡ï¼ŒåŸºæ–¼ Ultralytics å®˜æ–¹æ–‡ä»¶å’Œç¤¾å€è¨è«–ã€‚

#### 1. **Batch Size çš„è€ƒé‡**
   - **å–® GPU**ï¼šBatch size ç›´æ¥å— GPU è¨˜æ†¶é«”é™åˆ¶ï¼ˆä¾‹å¦‚ A100 ç´„ 40GBï¼Œå¯æ”¯æ´è¼ƒå¤§ batch å¦‚ 32~64ï¼Œè¦–æ¨¡å‹å’Œè³‡æ–™é›†è€Œå®šï¼‰ã€‚å»ºè­°ä½¿ç”¨æœ€å¤§å¯å®¹ç´çš„ batch size ä»¥å……åˆ†åˆ©ç”¨ GPUï¼Œåˆ©ç”¨ç‡å¯é” 60%~80%ï¼Œé¿å…è¨˜æ†¶é«”æº¢å‡ºï¼ˆOut of Memory, OOMï¼‰ã€‚åœ¨ Ultralytics ä¸­ï¼Œå¯è¨­ `batch=-1` è‡ªå‹•è¨ˆç®—ï¼ˆé è¨­ 60% è¨˜æ†¶é«”åˆ©ç”¨ç‡ï¼‰ã€‚
   - **å¤š GPU**ï¼šç¸½ batch size å¯ç·šæ€§å¢åŠ ï¼ˆä¾‹å¦‚ 2 å¼µ GPU æ™‚ï¼Œç¸½ batch = æ¯ GPU batch Ã— GPU æ•¸ï¼‰ï¼Œä½†æ¯å¼µ GPU çš„å¯¦éš› batch size éœ€ç¶­æŒä¸€è‡´ï¼Œä»¥ç¢ºä¿æ¢¯åº¦åŒæ­¥ã€‚å»ºè­°å…ˆåœ¨å–® GPU æ‰¾åˆ°ç©©å®š batch sizeï¼ˆå¦‚ 16ï¼‰ï¼Œç„¶å¾Œåœ¨å¤š GPU æ™‚å°‡ç¸½ batch size æ”¾å¤§ï¼ˆä¾‹å¦‚ 32ï¼‰ï¼Œè€Œéæ¯ GPU éƒ½ç”¨åŸå¤§å°ã€‚é€™èƒ½åŠ é€Ÿè¨“ç·´ï¼ˆä¾‹å¦‚ 8 å¼µ GPU å¯åŠ é€Ÿ 6.5 å€ï¼‰ï¼Œä½†è‹¥ç¸½ batch éå¤§ï¼Œå¯èƒ½å°è‡´æ¢¯åº¦ä¼°è¨ˆä¸æº–ç¢ºï¼Œå½±éŸ¿æ³›åŒ–ã€‚
   - **èª¿æ•´å»ºè­°**ï¼šå¾å–® GPU çš„ batch size é–‹å§‹ï¼Œé€æ­¥æ¸¬è©¦å¤š GPU è¨­å®šã€‚è‹¥è¨˜æ†¶é«”ä¸è¶³ï¼Œé™ä½æ¯ GPU batch æˆ–ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´ï¼ˆAMPï¼‰ã€‚å° batchï¼ˆ<64ï¼‰æ™‚ï¼Œéœ€ç´¯ç©æ¢¯åº¦ï¼ˆgradient accumulationï¼‰ä»¥æ¨¡æ“¬å¤§ batch æ•ˆæœã€‚

#### 2. **Learning Rate (LR) çš„è€ƒé‡**
   - **å–® GPU**ï¼šé è¨­åˆå§‹ LR ç‚º 0.01ï¼ˆSGDï¼‰æˆ– 0.001ï¼ˆAdamï¼‰ï¼Œæœ€çµ‚ LR ç‚ºåˆå§‹çš„ 0.01 å€ã€‚ä½¿ç”¨ cosine schedulerï¼ˆ`cos_lr=True`ï¼‰å¯å¹³æ»‘èª¿æ•´ï¼Œé¿å…éåº¦æŒ¯ç›ªã€‚
   - **å¤š GPU**ï¼šç”±æ–¼ç¸½ batch size å¢åŠ ï¼Œå»ºè­°**ç·šæ€§ç¸®æ”¾è¦å‰‡ï¼ˆLinear Scaling Ruleï¼‰**ï¼šæ–° LR = åŸ LR Ã— (ç¸½ batch size / å–® GPU batch size)ã€‚ä¾‹å¦‚ï¼Œå¾å–® GPU batch=16 è½‰åˆ° 4 å¼µ GPUï¼ˆç¸½ batch=64ï¼‰ï¼Œå‰‡ LR æ”¾å¤§ 4 å€ã€‚é€™èƒ½ç¶­æŒæ¢¯åº¦æ›´æ–°çš„ä¸€è‡´æ€§ï¼Œé˜²æ­¢è¨“ç·´ä¸ç©©å®šã€‚åŒæ™‚ï¼Œå»¶é•· warmup epochsï¼ˆé è¨­ 3 epochsï¼‰è‡³ 5~10ï¼Œä»¥æ¼¸é€²å¼å¾ä½ LR æš–æ©Ÿã€‚
   - **èª¿æ•´å»ºè­°**ï¼šç›£æ§æå¤±æ›²ç·šï¼Œè‹¥å¤š GPU æ™‚æå¤±ä¸Šå‡éå¿«ï¼Œé™ä½ LR 10%~20%ï¼›åä¹‹è‹¥æ”¶æ–‚æ…¢ï¼Œå‰‡å¾®å¢ã€‚Weight decayï¼ˆæ¬Šé‡è¡°æ¸›ï¼‰ä¹Ÿéœ€éš¨ batch size ç¸®æ”¾ï¼ˆä¾‹å¦‚æ”¾å¤§ batch æ™‚ï¼Œweight decay ä¹Ÿç·šæ€§æ”¾å¤§ï¼‰ã€‚

#### 3. **å…¶ä»–ç›¸é—œè¶…åƒæ•¸çš„è€ƒé‡**
   - **Warmup Epochs**ï¼šå¤š GPU æ™‚å»ºè­°å¢åŠ ï¼ˆä¾‹å¦‚å¾ 3 è‡³ 5ï¼‰ï¼Œä»¥é©æ‡‰æ›´å¤§ batch çš„æ¢¯åº¦è®Šç•°ã€‚
   - **Momentum å’Œ Weight Decay**ï¼šéš¨ batch size ç¸®æ”¾ï¼ˆä¾‹å¦‚ momentum é è¨­ 0.937ï¼Œweight decay é è¨­ 0.0005ï¼‰ï¼Œå¤§ batch æ™‚å¯ç•¥å¢ä»¥ç©©å®šè¨“ç·´ã€‚
   - **Epochs å’Œ Optimizer**ï¼šå¤š GPU ä¸éœ€è®Š epochsï¼ˆé è¨­ 100~300ï¼‰ï¼Œä½† AdamW å¸¸å„ªæ–¼ SGD åœ¨å¤§ batch æƒ…å¢ƒã€‚ç¸½è¨“ç·´æ™‚é–“æœƒç¸®çŸ­ï¼Œä½†ç¸½è¨ˆç®—é‡ï¼ˆFLOPsï¼‰ç›¸ä¼¼ã€‚
   - **é€šç”¨æç¤º**ï¼šä½¿ç”¨ `device=[0,1,2]` æŒ‡å®š GPUï¼ˆæˆ– `device=-1` è‡ªå‹•é¸é–’ç½® GPUï¼‰ã€‚åœ¨ YAML è¨­å®šæª”ï¼ˆå¦‚ `hyp.scratch-high.yaml`ï¼‰ä¸­èª¿æ•´é€™äº›åƒæ•¸ï¼Œä¸¦é€é Weights & Biases (W&B) è¨˜éŒ„å¯¦é©—æ¯”è¼ƒå–®/å¤š GPU æ•ˆæœã€‚

| è¶…åƒæ•¸       | å–® GPU å»ºè­°                  | å¤š GPU å»ºè­°ï¼ˆä»¥ 4 å¼µç‚ºä¾‹ï¼‰          | ä¸»è¦è€ƒé‡                  |
|--------------|------------------------------|------------------------------------|---------------------------|
| **Batch Size** | 16~32ï¼ˆä¾è¨˜æ†¶é«”ï¼‰           | ç¸½ 64ï¼ˆæ¯ GPU 16ï¼‰                 | ç·šæ€§æ”¾å¤§ç¸½å¤§å°ï¼Œé¿å… OOM |
| **Learning Rate (lr0)** | 0.01                        | 0.04ï¼ˆÃ—4 ç¸®æ”¾ï¼‰                    | ç·šæ€§ç¸®æ”¾ï¼Œé… warmup       |
| **Warmup Epochs** | 3                           | 5~10                               | ç©©å®šå¤§ batch æ¢¯åº¦         |
| **Weight Decay** | 0.0005                      | 0.002ï¼ˆÃ—4 ç¸®æ”¾ï¼‰                   | ç¶­æŒæ­£å‰‡åŒ–ä¸€è‡´            |

ç¸½çµä¾†èªªï¼Œå¾å–® GPU è½‰å¤š GPU æ™‚ï¼Œé‡é»æ˜¯ä¿æŒ**æœ‰æ•ˆç¸½ batch size** ä¸è®Šæˆ–é©åº¦æ”¾å¤§ï¼Œä¸¦åŒæ­¥èª¿æ•´ LR å’Œ warmupï¼Œä»¥ç¢ºä¿æ¨¡å‹æ•ˆèƒ½ä¸€è‡´ã€‚å»ºè­°å…ˆå°è¦æ¨¡æ¸¬è©¦ï¼ˆä¾‹å¦‚ COCO å­é›†ï¼‰ï¼Œä¸¦åƒè€ƒ Ultralytics çš„ hyperparameter tuning å·¥å…·è‡ªå‹•å„ªåŒ–ã€‚è‹¥é‡ç‰¹å®šç¡¬é«”å•é¡Œï¼Œå¯æŸ¥è©¢ GitHub issues æ±‚åŠ©ã€‚


---
# Ultralytics å¥—ä»¶èƒ½å¦è·‘Kaggle æä¾›å…è²»çš„ TPU è³‡æº

Ultralytics å¥—ä»¶ï¼ˆåŒ…æ‹¬ YOLOv8ã€YOLOv11 ç­‰æ¨¡å‹ï¼‰èƒ½å¤ åœ¨ Kaggle çš„ TPU åŠ é€Ÿå™¨ä¸Šé‹è¡Œå’Œè¨“ç·´ã€‚Kaggle æä¾›å…è²»çš„ TPU è³‡æºï¼ˆå¦‚ TPU v2-8 æˆ– v3-8ï¼‰ï¼ŒUltralytics é€é PyTorch/XLA æ•´åˆä¾†æ”¯æ´ TPUï¼Œé€™ä½¿å¾—è¨“ç·´å¤§å‹ç‰©ä»¶åµæ¸¬æ¨¡å‹è®Šå¾—é«˜æ•ˆä¸”ç„¡éœ€é¡å¤–ç¡¬é«”æˆæœ¬ã€‚

### ä¸»è¦æ”¯æ´ç´°ç¯€ï¼š
- **å®˜æ–¹ç¢ºèª**ï¼šUltralytics çš„å®˜æ–¹æ–‡ä»¶æ˜ç¢ºæŒ‡å‡ºï¼Œå¯ä»¥ä½¿ç”¨ Kaggle çš„ GPU/TPU è³‡æºä¾†è¨“ç·´ YOLO æ¨¡å‹ã€‚Kaggle ç’°å¢ƒé è£ PyTorch å’Œ TensorFlowï¼Œè®“å®‰è£ Ultralytics è®Šå¾—ç°¡å–®ã€‚
- **åŸ·è¡Œæ™‚é–“é™åˆ¶**ï¼šæ¯å€‹ TPU å·¥ä½œéšæ®µæœ€å¤š 9 å°æ™‚ï¼Œé©åˆä¸­å¤§å‹è³‡æ–™é›†è¨“ç·´ï¼Œä½†è‹¥éœ€æ›´é•·æ™‚é–“ï¼Œå¯åˆ†éšæ®µåŸ·è¡Œæˆ–ä½¿ç”¨ GPU æ›¿ä»£ã€‚
- **å®‰è£èˆ‡ä½¿ç”¨æ­¥é©Ÿ**ï¼ˆåœ¨ Kaggle Notebook ä¸­ï¼‰ï¼š
  1. å»ºç«‹æ–° Notebookï¼Œä¸¦åœ¨å³å´é¢æ¿é¸æ“‡ã€ŒTPUã€åŠ é€Ÿå™¨ã€‚
  2. å®‰è£ Ultralyticsï¼š`!pip install ultralytics`ã€‚
  3. è¼‰å…¥ PyTorch/XLAï¼ˆè‹¥éœ€ï¼‰ï¼š`!pip install cloud-tpu-client`ï¼ˆKaggle é€šå¸¸é è£ï¼‰ã€‚
  4. ç¯„ä¾‹è¨“ç·´ç¨‹å¼ç¢¼ï¼š
     ```python:disable-run
     from ultralytics import YOLO
     import torch_xla.core.xla_model as xm  # è‹¥éœ€ TPU ç‰¹å®šè¨­å®š

     model = YOLO('yolo11n.pt')  # æˆ–å…¶ä»–æ¨¡å‹
     results = model.train(data='your_dataset.yaml', epochs=100, device='tpu')  # æŒ‡å®š device='tpu'
     ```
     æ³¨æ„ï¼šéœ€ç¢ºä¿è³‡æ–™é›†ä¸Šå‚³è‡³ Kaggle Datasetsï¼Œä¸¦åœ¨ YAML æª”ä¸­æŒ‡å®šè·¯å¾‘ã€‚TPU è¨“ç·´æ™‚ï¼Œbatch size éœ€èª¿æ•´ä»¥é©æ‡‰ TPU å¢é›†ï¼ˆä¾‹å¦‚ä½¿ç”¨ `batch=16` èµ·ï¼‰ï¼Œä¸¦å•Ÿç”¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰ä»¥å„ªåŒ–æ•ˆèƒ½ã€‚

### æ³¨æ„äº‹é …ï¼š
- **ç›¸å®¹æ€§**ï¼šUltralytics ä¸»è¦åŸºæ–¼ PyTorchï¼ŒTPU æ”¯æ´è‰¯å¥½ï¼Œä½†è‹¥ä½¿ç”¨é€²éšåŠŸèƒ½ï¼ˆå¦‚è‡ªè¨‚ Trackerï¼‰ï¼Œå¯èƒ½éœ€é¡å¤–èª¿æ•´ç¨‹å¼ç¢¼ã€‚å®˜æ–¹å»ºè­°å¾å°è¦æ¨¡æ¸¬è©¦é–‹å§‹ï¼Œé¿å…è¨˜æ†¶é«”æº¢å‡ºã€‚
- **æ•ˆèƒ½**ï¼šTPU åœ¨å¤§ batch è¨“ç·´æ™‚è¡¨ç¾å„ªç•°ï¼Œèƒ½åŠ é€Ÿ YOLO æ¨¡å‹çš„æ”¶æ–‚ï¼Œä½†ä¸å¦‚ GPU éˆæ´»æ–¼å°æ¨¡å‹æ¨è«–ã€‚
- è‹¥é‡å•é¡Œï¼Œå¯åƒè€ƒ Ultralytics GitHub issues æˆ– Kaggle è«–å£‡è¨è«– TPU ç‰¹å®šè¨­å®šã€‚

ç¸½ä¹‹ï¼ŒUltralytics åœ¨ Kaggle TPU ä¸Šé‹è¡Œé †æš¢ï¼Œæ˜¯å…è²»è¨“ç·´ YOLO æ¨¡å‹çš„çµ•ä½³é¸æ“‡ã€‚è‹¥éœ€å®Œæ•´ Notebook ç¯„ä¾‹ï¼Œå»ºè­°ç›´æ¥åœ¨ Kaggle æœå°‹ã€ŒUltralytics YOLO TPUã€ã€‚

---
---


---
---
